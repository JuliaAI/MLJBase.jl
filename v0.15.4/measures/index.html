<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Measures · MLJBase.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">MLJBase.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Measures</a><ul class="internal"><li><a class="tocitem" href="#Helper-functions-1"><span>Helper functions</span></a></li><li><a class="tocitem" href="#Continuous-loss-functions-1"><span>Continuous loss functions</span></a></li><li><a class="tocitem" href="#Confusion-matrix-1"><span>Confusion matrix</span></a></li><li><a class="tocitem" href="#Finite-loss-functions-1"><span>Finite loss functions</span></a></li></ul></li><li><a class="tocitem" href="../resampling/">Resampling</a></li><li><a class="tocitem" href="../composition/">Composition</a></li><li><a class="tocitem" href="../datasets/">Datasets</a></li><li><a class="tocitem" href="../distributions/">Distributions</a></li><li><a class="tocitem" href="../openml/">OpenML</a></li><li><a class="tocitem" href="../utilities/">Utilities</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Measures</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Measures</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/master/docs/src/measures.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Measures-1"><a class="docs-heading-anchor" href="#Measures-1">Measures</a><a class="docs-heading-anchor-permalink" href="#Measures-1" title="Permalink"></a></h1><h2 id="Helper-functions-1"><a class="docs-heading-anchor" href="#Helper-functions-1">Helper functions</a><a class="docs-heading-anchor-permalink" href="#Helper-functions-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="MLJBase.metadata_measure-Tuple{Any}" href="#MLJBase.metadata_measure-Tuple{Any}"><code>MLJBase.metadata_measure</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">metadata_measure(T; kw...)</code></pre><p>Helper function to write the metadata for a single measure.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/measures.jl#LL114-L118">source</a></section></article><h2 id="Continuous-loss-functions-1"><a class="docs-heading-anchor" href="#Continuous-loss-functions-1">Continuous loss functions</a><a class="docs-heading-anchor-permalink" href="#Continuous-loss-functions-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="MLJBase.l1" href="#MLJBase.l1"><code>MLJBase.l1</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">l1(ŷ, y)
l1(ŷ, y, w)</code></pre><p>L1 per-observation loss.</p><p>For more information, run <code>info(l1)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/continuous.jl#LL131-L138">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.l2" href="#MLJBase.l2"><code>MLJBase.l2</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">l2(ŷ, y)
l2(ŷ, y, w)</code></pre><p>L2 per-observation loss.</p><p>For more information, run <code>info(l2)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/continuous.jl#LL97-L104">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.log_cosh" href="#MLJBase.log_cosh"><code>MLJBase.log_cosh</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">log_cosh(ŷ, y)</code></pre><p>Log-Cosh per-observation loss:</p><p><span>$\text{Log-Cosh Loss} = log(cosh(ŷᵢ-yᵢ))$</span></p><p>where <code>yᵢ</code> is the target and <code>ŷᵢ</code> is the output.</p><p>For more information, run <code>info(log_cosh)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/continuous.jl#LL326-L336">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.mae" href="#MLJBase.mae"><code>MLJBase.mae</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">mae(ŷ, y)
mae(ŷ, y, w)</code></pre><p>Mean absolute error.</p><p><span>$\text{MAE} =  n^{-1}∑ᵢ|yᵢ-ŷᵢ|$</span> or <span>$\text{MAE} = n^{-1}∑ᵢwᵢ|yᵢ-ŷᵢ|$</span></p><p>For more information, run <code>info(mae)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/continuous.jl#LL5-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.mape" href="#MLJBase.mape"><code>MLJBase.mape</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia"> MAPE(; tol=esp())</code></pre><p>Mean Absolute Proportional Error:</p><p><span>$\text{MAPE} =  m^{-1}∑ᵢ|{(yᵢ-ŷᵢ) \over yᵢ}|$</span> where the sum is over indices such that <code>yᵢ &gt; tol</code> and <code>m</code> is the number of such indices.</p><p>For more information, run <code>info(mape)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/continuous.jl#LL283-L293">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.rms" href="#MLJBase.rms"><code>MLJBase.rms</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">rms(ŷ, y)
rms(ŷ, y, w)</code></pre><p>Root mean squared error:</p><p><span>$\text{RMS} = \sqrt{n^{-1}∑ᵢ|yᵢ-ŷᵢ|^2}$</span> or <span>$\text{RMS} = \sqrt{\frac{∑ᵢwᵢ|yᵢ-ŷᵢ|^2}{∑ᵢwᵢ}}$</span></p><p>For more information, run <code>info(rms)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/continuous.jl#LL51-L60">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.rmsl" href="#MLJBase.rmsl"><code>MLJBase.rmsl</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">rmsl(ŷ, y)</code></pre><p>Root mean squared logarithmic error:</p><p><span>$\text{RMSL} = n^{-1}∑ᵢ\log\left({yᵢ \over ŷᵢ}\right)$</span></p><p>For more information, run <code>info(rmsl)</code>.</p><p>See also <a href="#MLJBase.rmslp1"><code>rmslp1</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/continuous.jl#LL165-L175">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.rmslp1" href="#MLJBase.rmslp1"><code>MLJBase.rmslp1</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">rmslp1(ŷ, y)</code></pre><p>Root mean squared logarithmic error with an offset of 1:</p><p><span>$\text{RMSLP1} = n^{-1}∑ᵢ\log\left({yᵢ + 1 \over ŷᵢ + 1}\right)$</span></p><p>For more information, run <code>info(rmslp1)</code>.</p><p>See also <a href="#MLJBase.rmsl"><code>rmsl</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/continuous.jl#LL200-L210">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.rmsp" href="#MLJBase.rmsp"><code>MLJBase.rmsp</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">rmsp(ŷ, y)</code></pre><p>Root mean squared proportional loss:</p><p><span>$\text{RMSP} = m^{-1}∑ᵢ \left({yᵢ-ŷᵢ \over yᵢ}\right)^2$</span></p><p>where the sum is over indices such that <code>yᵢ≂̸0</code> and <code>m</code> is the number of such indices.</p><p>For more information, run <code>info(rmsp)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/continuous.jl#LL237-L248">source</a></section></article><h2 id="Confusion-matrix-1"><a class="docs-heading-anchor" href="#Confusion-matrix-1">Confusion matrix</a><a class="docs-heading-anchor-permalink" href="#Confusion-matrix-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="MLJBase.confusion_matrix-Tuple{AbstractArray{#s519,1} where #s519&lt;:CategoricalArrays.CategoricalValue,AbstractArray{#s518,1} where #s518&lt;:CategoricalArrays.CategoricalValue}" href="#MLJBase.confusion_matrix-Tuple{AbstractArray{#s519,1} where #s519&lt;:CategoricalArrays.CategoricalValue,AbstractArray{#s518,1} where #s518&lt;:CategoricalArrays.CategoricalValue}"><code>MLJBase.confusion_matrix</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">confusion_matrix(ŷ, y; rev=false)</code></pre><p>Computes the confusion matrix given a predicted <code>ŷ</code> with categorical elements and the actual <code>y</code>. Rows are the predicted class, columns the ground truth. The ordering follows that of <code>levels(y)</code>.</p><p><strong>Keywords</strong></p><ul><li><code>rev=false</code>: in the binary case, this keyword allows to swap the ordering of              classes.</li><li><code>perm=[]</code>:   in the general case, this keyword allows to specify a permutation              re-ordering the classes.</li><li><code>warn=true</code>: whether to show a warning in case <code>y</code> does not have scientific              type <code>OrderedFactor{2}</code> (see note below).</li></ul><p><strong>Note</strong></p><p>To decrease the risk of unexpected errors, if <code>y</code> does not have scientific type <code>OrderedFactor{2}</code> (and so does not have a &quot;natural ordering&quot; negative-positive), a warning is shown indicating the current order unless the user explicitly specifies either <code>rev</code> or <code>perm</code> in which case it&#39;s assumed the user is aware of the class ordering.</p><p>The <code>confusion_matrix</code> is a measure (although neither a score nor a loss) and so may be specified as such in calls to <code>evaluate</code>, <code>evaluate!</code>, although not in <code>TunedModel</code>s.  In this case, however, there no way to specify an ordering different from <code>levels(y)</code>, where <code>y</code> is the target. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/confusion_matrix.jl#LL32-L63">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.ConfusionMatrix" href="#MLJBase.ConfusionMatrix"><code>MLJBase.ConfusionMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ConfusionMatrix{C}</code></pre><p>Confusion matrix with <code>C ≥ 2</code> classes. Rows correspond to predicted values and columns to the ground truth.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/confusion_matrix.jl#LL1-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.ConfusionMatrix-Tuple{Array{Int64,2},Array{String,1}}" href="#MLJBase.ConfusionMatrix-Tuple{Array{Int64,2},Array{String,1}}"><code>MLJBase.ConfusionMatrix</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ConfusionMatrix(m, labels)</code></pre><p>Instantiates a confusion matrix out of a square integer matrix <code>m</code>. Rows are the predicted class, columns the ground truth. See also the <a href="https://en.wikipedia.org/wiki/Confusion_matrix">wikipedia article</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/confusion_matrix.jl#LL12-L19">source</a></section></article><h2 id="Finite-loss-functions-1"><a class="docs-heading-anchor" href="#Finite-loss-functions-1">Finite loss functions</a><a class="docs-heading-anchor-permalink" href="#Finite-loss-functions-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="MLJBase.accuracy" href="#MLJBase.accuracy"><code>MLJBase.accuracy</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">accuracy</code></pre><p>Classification accuracy; aliases: <code>accuracy</code>.</p><pre><code class="language-none">accuracy(ŷ, y)
accuracy(ŷ, y, w)
accuracy(conf_mat)</code></pre><p>Returns the accuracy of the (point) predictions <code>ŷ</code>, given true observations <code>y</code>, optionally weighted by the weights <code>w</code>. All three arguments must be abstract vectors of the same length. This metric is invariant to class labelling and can be used for multiclass classification.</p><p>For more information, run <code>info(accuracy)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL266-L282">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.area_under_curve" href="#MLJBase.area_under_curve"><code>MLJBase.area_under_curve</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">area_under_curve</code></pre><p>Area under the ROC curve; aliases: <code>area_under_curve</code>, <code>auc</code></p><pre><code class="language-none">area_under_curve(ŷ, y)</code></pre><p>Return the area under the receiver operator characteristic (curve), for probabilistic predictions <code>ŷ</code>, given ground truth <code>y</code>. This metric is invariant to class labelling and can be used only for binary classification.</p><p>For more information, run <code>info(area_under_curve)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL427-L440">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.balanced_accuracy" href="#MLJBase.balanced_accuracy"><code>MLJBase.balanced_accuracy</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">balanced_accuracy</code></pre><p>Balanced classification accuracy; aliases: <code>balanced_accuracy</code>, <code>bacc</code>, <code>bac</code>.</p><pre><code class="language-none">balanced_accuracy(ŷ, y [, w])
balanced_accuracy(conf_mat)</code></pre><p>Return the balanced accuracy of the point prediction <code>ŷ</code>, given true observations <code>y</code>, optionally weighted by <code>w</code>. The balanced accuracy takes into consideration class imbalance. All  three arguments must have the same length. This metric is invariant to class labelling and can be used for multiclass classification.</p><p>For more information, run <code>info(balanced_accuracy)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL305-L321">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.cross_entropy" href="#MLJBase.cross_entropy"><code>MLJBase.cross_entropy</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">cross_entropy</code></pre><p>Cross entropy loss with probabilities clamped between <code>eps()</code> and <code>1-eps()</code>; aliases: <code>cross_entropy</code>.</p><pre><code class="language-none">ce = CrossEntropy(; eps=eps())
ce(ŷ, y)</code></pre><p>Given an abstract vector of distributions <code>ŷ</code> and an abstract vector of true observations <code>y</code>, return the corresponding cross-entropy loss (aka log loss) scores.</p><p>Since the score is undefined in the case of the true observation has predicted probability zero, probablities are clipped between <code>eps</code> and <code>1-eps</code> where <code>eps</code> can be specified.</p><p>If <code>sᵢ</code> is the predicted probability for the true class <code>yᵢ</code> then the score for that example is given by</p><pre><code class="language-none">-log(clamp(sᵢ, eps, 1-eps))</code></pre><p>For more information, run <code>info(cross_entropy)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL27-L49">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.false_discovery_rate" href="#MLJBase.false_discovery_rate"><code>MLJBase.false_discovery_rate</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">false_discovery_rate</code></pre><p>false discovery rate; aliases: <code>false_discovery_rate</code>, <code>falsediscovery_rate</code>, <code>fdr</code>.</p><pre><code class="language-none">false_discovery_rate(ŷ, y)</code></pre><p>False discovery rate for observations <code>ŷ</code> and ground truth <code>y</code>. Assigns <code>false</code> to first element of <code>levels(y)</code>. To reverse roles, use <code>FalseDiscoveryRate(rev=true)</code> instead of <code>false_discovery_rate</code>.</p><p>For more information, run <code>info(false_discovery_rate)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL763-L776">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.false_negative" href="#MLJBase.false_negative"><code>MLJBase.false_negative</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">false_negative</code></pre><p>Number of false negatives; aliases: <code>false_negative</code>, <code>falsenegative</code>.</p><pre><code class="language-none">false_negative(ŷ, y)</code></pre><p>Number of false positives for observations <code>ŷ</code> and ground truth <code>y</code>. Assigns <code>false</code> to first element of <code>levels(y)</code>. To reverse roles, use <code>FalseNegative(rev=true)</code> instead of <code>false_negative</code>.</p><p>For more information, run <code>info(false_negative)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL661-L674">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.false_negative_rate" href="#MLJBase.false_negative_rate"><code>MLJBase.false_negative_rate</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">false_negative_rate</code></pre><p>false negative rate; aliases: <code>false_negative_rate</code>, <code>falsenegative_rate</code>, <code>fnr</code>, <code>miss_rate</code>.</p><pre><code class="language-none">false_negative_rate(ŷ, y)</code></pre><p>False negative rate for observations <code>ŷ</code> and ground truth <code>y</code>. Assigns <code>false</code> to first element of <code>levels(y)</code>. To reverse roles, use <code>FalseNegativeRate(rev=true)</code> instead of <code>false_negative_rate</code>.</p><p>For more information, run <code>info(false_negative_rate)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL744-L757">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.false_positive" href="#MLJBase.false_positive"><code>MLJBase.false_positive</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">false_positive</code></pre><p>Number of false positives; aliases: <code>false_positive</code>, <code>falsepositive</code>.</p><pre><code class="language-none">false_positive(ŷ, y)</code></pre><p>Number of false positives for observations <code>ŷ</code> and ground truth <code>y</code>. Assigns <code>false</code> to first element of <code>levels(y)</code>. To reverse roles, use <code>FalsePositive(rev=true)</code> instead of <code>false_positive</code>.</p><p>For more information, run <code>info(false_positive)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL642-L656">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.false_positive_rate" href="#MLJBase.false_positive_rate"><code>MLJBase.false_positive_rate</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">false_positive_rate</code></pre><p>false positive rate; aliases: <code>false_positive_rate</code>, <code>falsepositive_rate</code>, <code>fpr</code>, <code>fallout</code>.</p><pre><code class="language-none">false_positive_rate(ŷ, y)</code></pre><p>False positive rate for observations <code>ŷ</code> and ground truth <code>y</code>. Assigns <code>false</code> to first element of <code>levels(y)</code>. To reverse roles, use <code>FalsePositiveRate(rev=true)</code> instead of <code>false_positive_rate</code>.</p><p>For more information, run <code>info(false_positive_rate)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL724-L737">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.matthews_correlation" href="#MLJBase.matthews_correlation"><code>MLJBase.matthews_correlation</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">matthews_correlation</code></pre><p>Matthew&#39;s correlation; aliases: <code>matthews_correlation</code>, <code>mcc</code></p><pre><code class="language-none">matthews_correlation(ŷ, y)
matthews_correlation(conf_mat)</code></pre><p>Return Matthews&#39; correlation coefficient corresponding to the point prediction <code>ŷ</code>, given true observations <code>y</code>. This metric is invariant to class labelling and can be used for multiclass classification.</p><p>For more information, run <code>info(matthews_correlation)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL364-L378">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.misclassification_rate" href="#MLJBase.misclassification_rate"><code>MLJBase.misclassification_rate</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">misclassification_rate</code></pre><p>misclassification rate; aliases: <code>misclassification_rate</code>, <code>mcr</code>.</p><pre><code class="language-none">misclassification_rate(ŷ, y)
misclassification_rate(ŷ, y, w)
misclassification_rate(conf_mat)</code></pre><p>Returns the rate of misclassification of the (point) predictions <code>ŷ</code>, given true observations <code>y</code>, optionally weighted by the weights <code>w</code>. All three arguments must be abstract vectors of the same length. A confusion matrix can also be passed as argument. This metric is invariant to class labelling and can be used for multiclass classification.</p><p>For more information, run <code>info(misclassification_rate)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL220-L237">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.negative_predictive_value" href="#MLJBase.negative_predictive_value"><code>MLJBase.negative_predictive_value</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">negative_predictive_value</code></pre><p>negative predictive value; aliases: <code>negative_predictive_value</code>, <code>negativepredictive_value</code>, <code>npv</code>.</p><pre><code class="language-none">negative_predictive_value(ŷ, y)</code></pre><p>Negative predictive value for observations <code>ŷ</code> and ground truth <code>y</code>. Assigns <code>false</code> to first element of <code>levels(y)</code>. To reverse roles, use <code>NPV(rev=true)</code> instead of <code>negative_predictive_value</code>.</p><p>For more information, run <code>info(negative_predictive_value)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL783-L796">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.positive_predictive_value" href="#MLJBase.positive_predictive_value"><code>MLJBase.positive_predictive_value</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">positive_predictive_value</code></pre><p>positive predictive value (aka precision); aliases: <code>positive_predictive_value</code>, <code>ppv</code>, <code>Precision()</code>, <code>positivepredictive_value</code>. </p><pre><code class="language-none">positive_predictive_value(ŷ, y)</code></pre><p>Positive predictive value for observations <code>ŷ</code> and ground truth <code>y</code>. Assigns <code>false</code> to first element of <code>levels(y)</code>. To reverse roles, use <code>Precision(rev=true)</code> instead of <code>positive_predictive_value</code>.</p><p>For more information, run <code>info(positive_predictive_value)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL801-L814">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.true_negative" href="#MLJBase.true_negative"><code>MLJBase.true_negative</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">true_negative</code></pre><p>Number of true negatives; aliases: <code>true_negative</code>, <code>truenegative</code>.</p><pre><code class="language-none">true_negative(ŷ, y)</code></pre><p>Number of true negatives for observations <code>ŷ</code> and ground truth <code>y</code>. Assigns <code>false</code> to first element of <code>levels(y)</code>. To reverse roles, use <code>TrueNegative(rev=true)</code> instead of <code>true_negative</code>.</p><p>For more information, run <code>info(true_negative)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL623-L637">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.true_negative_rate" href="#MLJBase.true_negative_rate"><code>MLJBase.true_negative_rate</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">true_negative_rate</code></pre><p>true negative rate; aliases: <code>true_negative_rate</code>, <code>truenegative_rate</code>, <code>tnr</code>, <code>specificity</code>, <code>selectivity</code>.</p><pre><code class="language-none">true_negative_rate(ŷ, y)</code></pre><p>True negative rate for observations <code>ŷ</code> and ground truth <code>y</code>. Assigns <code>false</code> to first element of <code>levels(y)</code>. To reverse roles, use <code>TrueNegativeRate(rev=true)</code> instead of <code>true_negative_rate</code>.</p><p>For more information, run <code>info(true_negative_rate)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL702-L715">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.true_positive" href="#MLJBase.true_positive"><code>MLJBase.true_positive</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">true_positive</code></pre><p>Number of true positives; aliases: <code>true_positive</code>, <code>truepositive</code>.</p><pre><code class="language-none">true_positive(ŷ, y)</code></pre><p>Number of true positives for observations <code>ŷ</code> and ground truth <code>y</code>. Assigns <code>false</code> to first element of <code>levels(y)</code>. To reverse roles, use <code>TruePositive(rev=true)</code> instead of <code>true_positive</code>.</p><p>For more information, run <code>info(true_positive)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL605-L618">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.true_positive_rate" href="#MLJBase.true_positive_rate"><code>MLJBase.true_positive_rate</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia">true_positive_rate</code></pre><p>True positive rate; aliases: <code>true_positive_rate</code>, <code>truepositive_rate</code>, <code>tpr</code>, <code>sensitivity</code>, <code>recall</code>, <code>hit_rate</code>.</p><pre><code class="language-none">true_positive_rate(ŷ, y)</code></pre><p>True positive rate for observations <code>ŷ</code> and ground truth <code>y</code>. Assigns <code>false</code> to first element of <code>levels(y)</code>. To reverse roles, use <code>TruePositiveRate(rev=true)</code> instead of <code>true_positive_rate</code>.</p><p>For more information, run <code>info(true_positive_rate)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL679-L692">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.BrierScore-Tuple{}" href="#MLJBase.BrierScore-Tuple{}"><code>MLJBase.BrierScore</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">BrierScore(; distribution=UnivariateFinite)(ŷ, y [, w])</code></pre><p>Given an abstract vector of distributions <code>ŷ</code> of type <code>distribution</code>, and an abstract vector of true observations <code>y</code>, return the corresponding Brier (aka quadratic) scores. Weight the scores using <code>w</code> if provided.</p><p>Currently only <code>distribution=UnivariateFinite</code> is supported, which is applicable to superivised models with <code>Finite</code> target scitype. In this case, if <code>p(y)</code> is the predicted probability for a <em>single</em> observation <code>y</code>, and <code>C</code> all possible classes, then the corresponding Brier score for that observation is given by</p><p><span>$2p(y) - \left(\sum_{η ∈ C} p(η)^2\right) - 1$</span></p><p>Note that <code>BrierScore()=BrierScore{UnivariateFinite}</code> has the alias <code>brier_score</code>.</p><p><em>Warning.</em> Here <code>BrierScore</code> is a &quot;score&quot; in the sense that bigger is better (with <code>0</code> optimal, and all other values negative). In Brier&#39;s original 1950 paper, and many other places, it has the opposite sign, despite the name. Moreover, the present implementation does not treat the binary case as special, so that the score may differ, in that case, by a factor of two from usage elsewhere.</p><p>For more information, run <code>info(BrierScore)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL103-L131">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.FScore" href="#MLJBase.FScore"><code>MLJBase.FScore</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FScore{β}(rev=nothing)</code></pre><p>One-parameter generalization, <span>$F_β$</span>, of the F-measure or balanced F-score.</p><p><a href="https://en.wikipedia.org/wiki/F1_score">Wikipedia entry</a></p><pre><code class="language-none">FScore{β}(ŷ, y)</code></pre><p>Evaluate <span>$F_β$</span> score on observations ,<code>ŷ</code>, given ground truth values, <code>y</code>.</p><p>By default, the second element of <code>levels(y)</code> is designated as <code>true</code>. To reverse roles, use <code>FScore{β}(rev=true)</code> instead of <code>FScore{β}</code>.</p><p>For more information, run <code>info(FScore)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL482-L499">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.roc_curve-Tuple{AbstractArray{#s533,1} where #s533&lt;:UnivariateFinite,AbstractArray{#s532,1} where #s532&lt;:CategoricalArrays.CategoricalValue}" href="#MLJBase.roc_curve-Tuple{AbstractArray{#s533,1} where #s533&lt;:UnivariateFinite,AbstractArray{#s532,1} where #s532&lt;:CategoricalArrays.CategoricalValue}"><code>MLJBase.roc_curve</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">fprs, tprs, ts = roc_curve(ŷ, y) = roc(ŷ, y)</code></pre><p>Return the ROC curve for a two-class probabilistic prediction <code>ŷ</code> given the ground  truth <code>y</code>. The true positive rates, false positive rates over a range of thresholds <code>ts</code> are returned. Note that if there are <code>k</code> unique scores, there are correspondingly  <code>k</code> thresholds and <code>k+1</code> &quot;bins&quot; over which the FPR and TPR are constant:</p><ul><li><code>[0.0 - thresh[1]]</code></li><li><code>[thresh[1] - thresh[2]]</code></li><li>...</li><li><code>[thresh[k] - 1]</code></li></ul><p>consequently, <code>tprs</code> and <code>fprs</code> are of length <code>k+1</code> if <code>ts</code> is of length <code>k</code>.</p><p>To draw the curve using your favorite plotting backend, do <code>plot(fprs, tprs)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL900-L917">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase._idx_unique_sorted-Tuple{AbstractArray{#s534,1} where #s534&lt;:Real}" href="#MLJBase._idx_unique_sorted-Tuple{AbstractArray{#s534,1} where #s534&lt;:Real}"><code>MLJBase._idx_unique_sorted</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">_idx_unique_sorted(v)</code></pre><p>Internal function to return the index of unique elements in <code>v</code> under the assumption that the vector <code>v</code> is sorted in decreasing order.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/23407a4ed45101c51eaaea6824c676e76fe5e576/src/measures/finite.jl#LL877-L882">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../resampling/">Resampling »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 4 November 2020 02:22">Wednesday 4 November 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
